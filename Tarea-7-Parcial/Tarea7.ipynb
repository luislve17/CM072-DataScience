{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 7 del curso CM-072\n",
    "\n",
    "* Nombre y apellidos: Luis Vasquez Espinoza\n",
    "* Fecha de presentación: 17 de octubre.\n",
    "\n",
    "LendingClub es una compañía de préstamos *peer-to-peer* que conecta directamente a los prestatarios con potenciales prestamistas/inversionistas.\n",
    "\n",
    "Construirás un modelo de clasificación para predecir si un préstamo realizado a través del LendingClub tiene probabilidad de no ser pagado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "loans = pd.read_csv(\"lending-club-data.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 . Carga en una variable de nombre `todo_columnas` el nombre de todas las columnas del conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'member_id',\n",
       " 'loan_amnt',\n",
       " 'funded_amnt',\n",
       " 'funded_amnt_inv',\n",
       " 'term',\n",
       " 'int_rate',\n",
       " 'installment',\n",
       " 'grade',\n",
       " 'sub_grade',\n",
       " 'emp_title',\n",
       " 'emp_length',\n",
       " 'home_ownership',\n",
       " 'annual_inc',\n",
       " 'is_inc_v',\n",
       " 'issue_d',\n",
       " 'loan_status',\n",
       " 'pymnt_plan',\n",
       " 'url',\n",
       " 'desc',\n",
       " 'purpose',\n",
       " 'title',\n",
       " 'zip_code',\n",
       " 'addr_state',\n",
       " 'dti',\n",
       " 'delinq_2yrs',\n",
       " 'earliest_cr_line',\n",
       " 'inq_last_6mths',\n",
       " 'mths_since_last_delinq',\n",
       " 'mths_since_last_record',\n",
       " 'open_acc',\n",
       " 'pub_rec',\n",
       " 'revol_bal',\n",
       " 'revol_util',\n",
       " 'total_acc',\n",
       " 'initial_list_status',\n",
       " 'out_prncp',\n",
       " 'out_prncp_inv',\n",
       " 'total_pymnt',\n",
       " 'total_pymnt_inv',\n",
       " 'total_rec_prncp',\n",
       " 'total_rec_int',\n",
       " 'total_rec_late_fee',\n",
       " 'recoveries',\n",
       " 'collection_recovery_fee',\n",
       " 'last_pymnt_d',\n",
       " 'last_pymnt_amnt',\n",
       " 'next_pymnt_d',\n",
       " 'last_credit_pull_d',\n",
       " 'collections_12_mths_ex_med',\n",
       " 'mths_since_last_major_derog',\n",
       " 'policy_code',\n",
       " 'not_compliant',\n",
       " 'status',\n",
       " 'inactive_loans',\n",
       " 'bad_loans',\n",
       " 'emp_length_num',\n",
       " 'grade_num',\n",
       " 'sub_grade_num',\n",
       " 'delinq_2yrs_zero',\n",
       " 'pub_rec_zero',\n",
       " 'collections_12_mths_zero',\n",
       " 'short_emp',\n",
       " 'payment_inc_ratio',\n",
       " 'final_d',\n",
       " 'last_delinq_none',\n",
       " 'last_record_none',\n",
       " 'last_major_derog_none']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solucion\n",
    "todo_columnas = list(loans)\n",
    "todo_columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 . La columna que contiene la información que queremos predecir se llama `malos_prestamos`. En esta columna, el valor 1 significa un préstamo riesgoso (malo), mientras que 0 significa un préstamos seguro.\n",
    "\n",
    "Para hacer el trabajo más intuitivo, crea una nueva columna `prestamos_seguros` con el siguiente valor:\n",
    "\n",
    "* +1 si es un préstamo seguro\n",
    "* -1 si es un préstamos riesgoso (malo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solucion\n",
    "loans['prestamos_seguros'] = loans['bad_loans'].apply(lambda x : +1 if x==0 else -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 . Calcula la distribución en porcentaje de préstamos malos y préstamos buenos (debe sumar 100%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 99457, -1: 23150})\n",
      "%P. Buenos:  0.8111853319957262\n",
      "%P. Malos:  0.18881466800427382\n",
      "Total:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Tu solución\n",
    "import collections\n",
    "\n",
    "counter = collections.Counter(loans['prestamos_seguros'])\n",
    "print(counter)\n",
    "porcentaje_buenos = counter[1]/len(loans['prestamos_seguros'])\n",
    "porcentaje_malos = counter[-1]/len(loans['prestamos_seguros'])\n",
    "print(\"%P. Buenos: \", porcentaje_buenos)\n",
    "print(\"%P. Malos: \", porcentaje_malos)\n",
    "print(\"Total: \", porcentaje_malos+porcentaje_buenos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 . Una manera de abordar conjuntos de datos desbalanceados es con un submuestreo  de la clase más grande hasta que la distribución de clases sea mitad y mitad. Vamos a realizar un submuestreo de los préstamos buenos para balancear nuestro conjunto de datos. Ello significa que vamos a descartar muchas observaciones. \n",
    "\n",
    "* Pon en una variable `prestamos_arriesgado` todos y solo los préstamos malos.\n",
    "* Pon en una variable `prestamos_seguros` una muestra aleatoria de préstamos buenos **del mismo tamaño** que la cantidad de préstamos malos. (Usa [pandas.DataFrame.sample](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sample.html) con el atributo `random_state=0`)\n",
    "* Junta en una nueva variable `prestamos_balanceados`, los dos grupos anteriores: `prestamos_arriesgados` y `prestamos_seguros`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46300"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tus soluciones\n",
    "prestamos_arriesgados = loans[loans['prestamos_seguros'] == -1]\n",
    "prestamos_seguros = loans[loans['prestamos_seguros'] == 1].sample(len(prestamos_arriesgados), random_state=0)\n",
    "prestamos_balanceados = prestamos_arriesgados.append(prestamos_seguros)\n",
    "len(prestamos_balanceados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 . Asigna a una variable `subconjunto_prestamos` sólo el siguiente subconjunto de características que son las que usaremos:\n",
    "\n",
    "```python\n",
    "caracteristica = ['grade',               # grade of the loan\n",
    "            'sub_grade',                 # sub-grade of the loan\n",
    "            'short_emp',                 # one year or less of employment\n",
    "            'emp_length_num',            # number of years of employment\n",
    "            'home_ownership',            # home_ownership status: own, mortgage or rent\n",
    "            'dti',                       # debt to income ratio\n",
    "            'purpose',                   # the purpose of the loan\n",
    "            'term',                      # the term of the loan\n",
    "            'last_delinq_none',          # has borrower had a delinquincy\n",
    "            'last_major_derog_none',     # has borrower had 90 day or worse rating\n",
    "            'revol_util',                # percent of available credit being used\n",
    "            'total_rec_late_fee',        # total late fees received to day\n",
    "           ]\n",
    "```\n",
    "\n",
    "Asimismo, asigna a una variable **`y`** los valores de la columna `prestamos_seguros`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu solucion\n",
    "# Asumiendo que se quiere utilizar el dataset balanceado creado en el ej. anterior\n",
    "caracteristica = ['grade',               # grade of the loan\n",
    "            'sub_grade',                 # sub-grade of the loan\n",
    "            'short_emp',                 # one year or less of employment\n",
    "            'emp_length_num',            # number of years of employment\n",
    "            'home_ownership',            # home_ownership status: own, mortgage or rent\n",
    "            'dti',                       # debt to income ratio\n",
    "            'purpose',                   # the purpose of the loan\n",
    "            'term',                      # the term of the loan\n",
    "            'last_delinq_none',          # has borrower had a delinquincy\n",
    "            'last_major_derog_none',     # has borrower had 90 day or worse rating\n",
    "            'revol_util',                # percent of available credit being used\n",
    "            'total_rec_late_fee',        # total late fees received to day\n",
    "           ]\n",
    "\n",
    "subconjunto_prestamos = prestamos_balanceados.loc[:,caracteristica]\n",
    "y = prestamos_balanceados['prestamos_seguros']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 .  Usando [pandas.get_dummies](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html) convierte las variables categóricas de `subconjunto_prestamos` en variables numéricas *one-hot*. Guarda el nuevo conjunto de datos en `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_emp</th>\n",
       "      <th>emp_length_num</th>\n",
       "      <th>dti</th>\n",
       "      <th>last_delinq_none</th>\n",
       "      <th>last_major_derog_none</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>total_rec_late_fee</th>\n",
       "      <th>grade_A</th>\n",
       "      <th>grade_B</th>\n",
       "      <th>grade_C</th>\n",
       "      <th>...</th>\n",
       "      <th>purpose_house</th>\n",
       "      <th>purpose_major_purchase</th>\n",
       "      <th>purpose_medical</th>\n",
       "      <th>purpose_moving</th>\n",
       "      <th>purpose_other</th>\n",
       "      <th>purpose_small_business</th>\n",
       "      <th>purpose_vacation</th>\n",
       "      <th>purpose_wedding</th>\n",
       "      <th>term_ 36 months</th>\n",
       "      <th>term_ 60 months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.55</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.08</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.08</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>91.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7.06</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    short_emp  emp_length_num    dti  last_delinq_none  last_major_derog_none  \\\n",
       "1           1               1   1.00                 1                      1   \n",
       "6           0               5   5.55                 1                      1   \n",
       "7           1               1  18.08                 1                      1   \n",
       "10          1               1  10.08                 1                      1   \n",
       "12          0               4   7.06                 1                      1   \n",
       "\n",
       "    revol_util  total_rec_late_fee  grade_A  grade_B  grade_C  \\\n",
       "1          9.4                 0.0        0        0        1   \n",
       "6         32.6                 0.0        0        0        0   \n",
       "7         36.5                 0.0        0        1        0   \n",
       "10        91.7                 0.0        0        0        1   \n",
       "12        55.5                 0.0        0        1        0   \n",
       "\n",
       "         ...         purpose_house  purpose_major_purchase  purpose_medical  \\\n",
       "1        ...                     0                       0                0   \n",
       "6        ...                     0                       0                0   \n",
       "7        ...                     0                       0                0   \n",
       "10       ...                     0                       0                0   \n",
       "12       ...                     0                       0                0   \n",
       "\n",
       "    purpose_moving  purpose_other  purpose_small_business  purpose_vacation  \\\n",
       "1                0              0                       0                 0   \n",
       "6                0              0                       1                 0   \n",
       "7                0              1                       0                 0   \n",
       "10               0              0                       0                 0   \n",
       "12               0              1                       0                 0   \n",
       "\n",
       "    purpose_wedding  term_ 36 months  term_ 60 months  \n",
       "1                 0                0                1  \n",
       "6                 0                0                1  \n",
       "7                 0                0                1  \n",
       "10                0                1                0  \n",
       "12                0                1                0  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tu solucion\n",
    "X = pd.get_dummies(subconjunto_prestamos)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 .  Empleando `sklearn.model_selection.train_test_split` separa el conjunto de datos en un 90% para entrenamiento y validación (`X_entrenamiento_val`, `y_entrenamiento_val`), y 10% para pruebas (`X_prueba`, `y_prueba`).\n",
    "\n",
    "Luego separa (`X_entrenamiento_val`, `y_entrenamiento_val`) en un 80% para entrenamiento (`X_entrenamiento`, `y_entrenamiento`) y 20% para validación (`X_val`, `y_val`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu solucion\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Particion 90,10\n",
    "X_entrenamiento_val, X_prueba, y_entrenamiento_val, y_prueba = train_test_split(X, y, test_size=0.1) \n",
    "X_entrenamiento, X_val, y_entrenamiento, y_val = train_test_split(X_entrenamiento_val, y_entrenamiento_val, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 . Entrena un modelo como Regresión Logística, Naive Bayes, KNN y un cuarto modelo de tu elección, con las siguientes indicaciones:\n",
    "\n",
    "* Utilizar el uso apropiado de la normalización (Scaling) de datos si fuese necesario.\n",
    "* El uso apropiado de una técnica para la selección de los mejores parámetros de cada modelo (p.ej. búsqueda grid o búsqueda aleatoria)\n",
    "* Reporte para cada modelo la exactitud , precisión y exhaustividad, F1-Score  **en el conjunto de pruebas.** y muestra la matriz de confusión.\n",
    "* Comenta tus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as m\n",
    "\n",
    "def showMetrics(y, y_predicted, f1_flag=False):\n",
    "    print(\"Total: \", len(y))\n",
    "    print(\"Exactitud no normalizada:\", m.accuracy_score(y, y_predicted, normalize=False))\n",
    "    print(\"Exactitud normalizada (no normaliz./total):\",m.accuracy_score(y, y_predicted, normalize=False)/len(y))\n",
    "    print(\"Presicion:\", m.precision_score(y, y_predicted))\n",
    "    print(\"Exhaustividad:\", m.recall_score(y, y_predicted))\n",
    "    if f1_flag:\n",
    "        print(\"F1-Score:\", m.f1_score(y, y_predicted))\n",
    "    matriz_confusion = m.confusion_matrix(y, y_predicted)\n",
    "    print(\"Matriz de conf:\\n\", matriz_confusion)\n",
    "    \n",
    "def showAllMetrics(X_train, X_test, X_val, y_train, y_test, y_val, model):\n",
    "    for text, y_real, current_X in zip([\"PRUEBA\", \"ENTRENAMIENTO\", \"VALIDACION\"],\n",
    "                                       [y_test, y_train, y_val],\n",
    "                                       [X_test, X_train, X_val]\n",
    "                                      ):\n",
    "        print(text)\n",
    "        print(\"_____________\")\n",
    "        showMetrics(y_real, model.predict(current_X), True if text==\"PRUEBA\" else False)\n",
    "        print(\"=========================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRUEBA\n",
      "_____________\n",
      "Total:  4630\n",
      "Exactitud no normalizada: 2954\n",
      "Exactitud normalizada (no normaliz./total): 0.6380129589632829\n",
      "Presicion: 0.6430071398572028\n",
      "Exhaustividad: 0.649554518455664\n",
      "F1-Score: 0.6462642465175179\n",
      "Matriz de conf:\n",
      " [[1423  850]\n",
      " [ 826 1531]]\n",
      "=========================================\n",
      "ENTRENAMIENTO\n",
      "_____________\n",
      "Total:  33336\n",
      "Exactitud no normalizada: 21577\n",
      "Exactitud normalizada (no normaliz./total): 0.6472582193424526\n",
      "Presicion: 0.6476293752635701\n",
      "Exhaustividad: 0.6452581032412965\n",
      "Matriz de conf:\n",
      " [[10827  5849]\n",
      " [ 5910 10750]]\n",
      "=========================================\n",
      "VALIDACION\n",
      "_____________\n",
      "Total:  8334\n",
      "Exactitud no normalizada: 5311\n",
      "Exactitud normalizada (no normaliz./total): 0.6372690184785217\n",
      "Presicion: 0.6341876208897486\n",
      "Exhaustividad: 0.6346479554802806\n",
      "Matriz de conf:\n",
      " [[2688 1513]\n",
      " [1510 2623]]\n",
      "=========================================\n",
      "< SELECCCIONANDO FEATURES VIA RFE>\n",
      "PRUEBA\n",
      "_____________\n",
      "Total:  4630\n",
      "Exactitud no normalizada: 2649\n",
      "Exactitud normalizada (no normaliz./total): 0.5721382289416846\n",
      "Presicion: 0.770893371757925\n",
      "Exhaustividad: 0.22698345354263894\n",
      "F1-Score: 0.3507046869878728\n",
      "Matriz de conf:\n",
      " [[2114  159]\n",
      " [1822  535]]\n",
      "=========================================\n",
      "ENTRENAMIENTO\n",
      "_____________\n",
      "Total:  33336\n",
      "Exactitud no normalizada: 19001\n",
      "Exactitud normalizada (no normaliz./total): 0.5699844012479002\n",
      "Presicion: 0.7514600908500974\n",
      "Exhaustividad: 0.2085234093637455\n",
      "Matriz de conf:\n",
      " [[15527  1149]\n",
      " [13186  3474]]\n",
      "=========================================\n",
      "VALIDACION\n",
      "_____________\n",
      "Total:  8334\n",
      "Exactitud no normalizada: 4783\n",
      "Exactitud normalizada (no normaliz./total): 0.5739140868730501\n",
      "Presicion: 0.7548161120840631\n",
      "Exhaustividad: 0.20856520687152189\n",
      "Matriz de conf:\n",
      " [[3921  280]\n",
      " [3271  862]]\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "# Tus soluciones\n",
    "# A. Usando regresion logistica\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_entrenamiento, y_entrenamiento)\n",
    "showAllMetrics(X_entrenamiento, X_prueba, X_val, y_entrenamiento, y_prueba, y_val, lr)\n",
    "print(\"< SELECCCIONANDO FEATURES VIA RFE>\")\n",
    "lr = RFE(lr, 3) # Seleccion de Features usando Recursive Feature Elimination\n",
    "lr.fit(X_entrenamiento, y_entrenamiento)\n",
    "showAllMetrics(X_entrenamiento, X_prueba, X_val, y_entrenamiento, y_prueba, y_val, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comentarios (Logistic Regression)\n",
    "\n",
    "Se notan scores similares con valores alrededor de 0.64. Posteriormente, habiendo aplicado la selección de features se nota un aumento considerable en la presición de las estimaciones para todos los bloques de datos *train_test_val*, aumentando hasta en un 10%; sin embargo la exactitud decae en un 10%, el F1-Score (ver modulos de PRUEBA) en un 30% y la exhaustividad en un alarmante 40%; esto debido a la eliminación de muchas características necesarias para la correcta clasificación. Considero que es mejor aplicar este modelo a la mayor cantidad de *features* disponibles o almenos sesgar la menor cantidad de columnas de la data original. El tiempo de entrenamiento optimizable al usar RFE no se distancia mucho del modelo original, por lo que optimizar el proceso tampoco es una buena razón para usarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRUEBA\n",
      "_____________\n",
      "Total:  4630\n",
      "Exactitud no normalizada: 2741\n",
      "Exactitud normalizada (no normaliz./total): 0.5920086393088553\n",
      "Presicion: 0.5618393234672304\n",
      "Exhaustividad: 0.9019940602460755\n",
      "F1-Score: 0.6923953753460348\n",
      "Matriz de conf:\n",
      " [[ 615 1658]\n",
      " [ 231 2126]]\n",
      "=========================================\n",
      "ENTRENAMIENTO\n",
      "_____________\n",
      "Total:  33336\n",
      "Exactitud no normalizada: 19650\n",
      "Exactitud normalizada (no normaliz./total): 0.5894528437724982\n",
      "Presicion: 0.5554436987322894\n",
      "Exhaustividad: 0.8941776710684274\n",
      "Matriz de conf:\n",
      " [[ 4753 11923]\n",
      " [ 1763 14897]]\n",
      "=========================================\n",
      "VALIDACION\n",
      "_____________\n",
      "Total:  8334\n",
      "Exactitud no normalizada: 4862\n",
      "Exactitud normalizada (no normaliz./total): 0.5833933285337173\n",
      "Presicion: 0.5492475040977499\n",
      "Exhaustividad: 0.8918461166223083\n",
      "Matriz de conf:\n",
      " [[1176 3025]\n",
      " [ 447 3686]]\n",
      "=========================================\n",
      "< SELECCCIONANDO FEATURES VIA RFE>\n",
      "PRUEBA\n",
      "_____________\n",
      "Total:  4630\n",
      "Exactitud no normalizada: 2259\n",
      "Exactitud normalizada (no normaliz./total): 0.4879049676025918\n",
      "Presicion: 0.36538461538461536\n",
      "Exhaustividad: 0.008061094611794654\n",
      "F1-Score: 0.0157741801577418\n",
      "Matriz de conf:\n",
      " [[2240   33]\n",
      " [2338   19]]\n",
      "=========================================\n",
      "ENTRENAMIENTO\n",
      "_____________\n",
      "Total:  33336\n",
      "Exactitud no normalizada: 16498\n",
      "Exactitud normalizada (no normaliz./total): 0.4949004079673626\n",
      "Presicion: 0.3013392857142857\n",
      "Exhaustividad: 0.008103241296518607\n",
      "Matriz de conf:\n",
      " [[16363   313]\n",
      " [16525   135]]\n",
      "=========================================\n",
      "VALIDACION\n",
      "_____________\n",
      "Total:  8334\n",
      "Exactitud no normalizada: 4150\n",
      "Exactitud normalizada (no normaliz./total): 0.497960163186945\n",
      "Presicion: 0.2892561983471074\n",
      "Exhaustividad: 0.008468424872973626\n",
      "Matriz de conf:\n",
      " [[4115   86]\n",
      " [4098   35]]\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "# B. Usando Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "m_naive_bayes = MultinomialNB()\n",
    "m_naive_bayes.fit(X_entrenamiento, y_entrenamiento)\n",
    "showAllMetrics(X_entrenamiento, X_prueba, X_val, y_entrenamiento, y_prueba, y_val, m_naive_bayes)\n",
    "print(\"< SELECCCIONANDO FEATURES VIA RFE>\")\n",
    "m_naive_bayes = RFE(m_naive_bayes, 10) # Seleccion de Features usando Recursive Feature Elimination\n",
    "m_naive_bayes.fit(X_entrenamiento, y_entrenamiento)\n",
    "showAllMetrics(X_entrenamiento, X_prueba, X_val, y_entrenamiento, y_prueba, y_val, m_naive_bayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comentarios (Naive Bayes)\n",
    "Inicialmente se observan scores aceptables, con exhaustividades bastante altas que evidencian *pocos falsos negativos*, por lo que el modelo al menos ahorra en no clasificar un dato como \"mal préstamo\" pudiendo evitar la mitad de la catástrofe financiera en favor al cliente; sin embargo la presición es muy baja, lo que podría tener como consecuencia habilitar préstamos que le cuesten más a la empresa *(Lending Club)* por no prever estos casos. Pero la tendencia de la clasificación anterior se mantiene: ni bien consideramos menos *features* de la data notamos un bajón de scores en todos los campos, especialmente para este modelo. Si bien la exactitud no se ven tan afectada (~-3%), la presición y exhaustividad evidencian cómo el modelo se vuelve directamente inútil. Mi conclusión para este caso: más (propiedades) es mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRUEBA\n",
      "_____________\n",
      "Total:  4630\n",
      "Exactitud no normalizada: 3573\n",
      "Exactitud normalizada (no normaliz./total): 0.7717062634989201\n",
      "Presicion: 0.7692626346313173\n",
      "Exhaustividad: 0.7878659312685617\n",
      "F1-Score: 0.7784531544749529\n",
      "Matriz de conf:\n",
      " [[1716  557]\n",
      " [ 500 1857]]\n",
      "=========================================\n",
      "ENTRENAMIENTO\n",
      "_____________\n",
      "Total:  33336\n",
      "Exactitud no normalizada: 25884\n",
      "Exactitud normalizada (no normaliz./total): 0.7764578833693304\n",
      "Presicion: 0.7696497598688063\n",
      "Exhaustividad: 0.7887755102040817\n",
      "Matriz de conf:\n",
      " [[12743  3933]\n",
      " [ 3519 13141]]\n",
      "=========================================\n",
      "VALIDACION\n",
      "_____________\n",
      "Total:  8334\n",
      "Exactitud no normalizada: 6438\n",
      "Exactitud normalizada (no normaliz./total): 0.7724982001439885\n",
      "Presicion: 0.7644833293922914\n",
      "Exhaustividad: 0.7822405032663925\n",
      "Matriz de conf:\n",
      " [[3205  996]\n",
      " [ 900 3233]]\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "# C. Usando KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X, y)\n",
    "showAllMetrics(X_entrenamiento, X_prueba, X_val, y_entrenamiento, y_prueba, y_val, knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comentarios (KNN)\n",
    "No me fue posible probar la selección de *features* para knn por el método recursivo habitual. Los scores obtenidos son muy buenos en todos los aspectos; no evidencian *overfitting* y dan la suficiente confianza como para aplicarse. Supongo que al ser KNN el único downfall es el tiempo de ejecución del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRUEBA\n",
      "_____________\n",
      "Total:  4630\n",
      "Exactitud no normalizada: 2931\n",
      "Exactitud normalizada (no normaliz./total): 0.6330453563714903\n",
      "Presicion: 0.6210448859455482\n",
      "Exhaustividad: 0.7161646160373356\n",
      "F1-Score: 0.6652216748768472\n",
      "Matriz de conf:\n",
      " [[1243 1030]\n",
      " [ 669 1688]]\n",
      "=========================================\n",
      "ENTRENAMIENTO\n",
      "_____________\n",
      "Total:  33336\n",
      "Exactitud no normalizada: 21127\n",
      "Exactitud normalizada (no normaliz./total): 0.6337592992560596\n",
      "Presicion: 0.6171500763278412\n",
      "Exhaustividad: 0.7037214885954381\n",
      "Matriz de conf:\n",
      " [[ 9403  7273]\n",
      " [ 4936 11724]]\n",
      "=========================================\n",
      "VALIDACION\n",
      "_____________\n",
      "Total:  8334\n",
      "Exactitud no normalizada: 5196\n",
      "Exactitud normalizada (no normaliz./total): 0.6234701223902088\n",
      "Presicion: 0.6056487576980251\n",
      "Exhaustividad: 0.6900556496491652\n",
      "Matriz de conf:\n",
      " [[2344 1857]\n",
      " [1281 2852]]\n",
      "=========================================\n",
      "< SELECCCIONANDO FEATURES VIA RFE>\n",
      "PRUEBA\n",
      "_____________\n",
      "Total:  4630\n",
      "Exactitud no normalizada: 2923\n",
      "Exactitud normalizada (no normaliz./total): 0.631317494600432\n",
      "Presicion: 0.625\n",
      "Exhaustividad: 0.6894357233771744\n",
      "F1-Score: 0.6556384910227961\n",
      "Matriz de conf:\n",
      " [[1298  975]\n",
      " [ 732 1625]]\n",
      "=========================================\n",
      "ENTRENAMIENTO\n",
      "_____________\n",
      "Total:  33336\n",
      "Exactitud no normalizada: 21234\n",
      "Exactitud normalizada (no normaliz./total): 0.6369690424766019\n",
      "Presicion: 0.6259255166316721\n",
      "Exhaustividad: 0.6799519807923169\n",
      "Matriz de conf:\n",
      " [[ 9906  6770]\n",
      " [ 5332 11328]]\n",
      "=========================================\n",
      "VALIDACION\n",
      "_____________\n",
      "Total:  8334\n",
      "Exactitud no normalizada: 5221\n",
      "Exactitud normalizada (no normaliz./total): 0.6264698824094073\n",
      "Presicion: 0.6131322094055013\n",
      "Exhaustividad: 0.6687636099685459\n",
      "Matriz de conf:\n",
      " [[2457 1744]\n",
      " [1369 2764]]\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier(max_depth=5)\n",
    "dtc.fit(X, y)\n",
    "showAllMetrics(X_entrenamiento, X_prueba, X_val, y_entrenamiento, y_prueba, y_val, dtc)\n",
    "print(\"< SELECCCIONANDO FEATURES VIA RFE>\")\n",
    "dtc = RFE(dtc, 35) # Seleccion de Features usando Recursive Feature Elimination\n",
    "dtc.fit(X_entrenamiento, y_entrenamiento)\n",
    "showAllMetrics(X_entrenamiento, X_prueba, X_val, y_entrenamiento, y_prueba, y_val, dtc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comentarios (DecisionTreeClassifier)\n",
    "Para mi sorpresa este modelo es el único que soporta la eliminación de características sin sufrir tanto en las métricas y optimizando el proceso de entrenamiento. Se notan valores similares antes y despues del sesgado y en ambos casos se producen scores más aceptables que el segundo o incluso el primer modelo. Si se necesita correr el modelo en sistemas low-end como embebidos esta es la mejor alternativa (si no se añade en consideración el tiempo de RFE)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
